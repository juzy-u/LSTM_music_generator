{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "# music21 is the library for editing music files, incl. MIDI.\n",
    "from music21 import * \n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total songs loaded 18\n"
     ]
    }
   ],
   "source": [
    "# Loading midi files whith metadata\n",
    "Songs = []\n",
    "directory = 'F:\\MusicNet\\КИШ\\табы тест без ритма'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and filename.endswith('.mid'):\n",
    "        f = converter.parse(f)\n",
    "        f.insert(0, metadata.Metadata())\n",
    "        f.metadata.title = filename\n",
    "        Songs.append(f)\n",
    "print('Total songs loaded', len(Songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose function \n",
    "# we need to transpose all songs to one key: C-major or parralel minor (A-minor)\n",
    "def transpose(song):\n",
    "  \n",
    "    key = song.analyze('key')\n",
    "    if key.mode == 'major':\n",
    "        i = interval.Interval(key.tonic, pitch.Pitch('C'))\n",
    "    elif key.mode == 'minor':\n",
    "        i = interval.Interval(key.tonic, pitch.Pitch('A'))\n",
    "    transposed_song = song.transpose(i)\n",
    "    # print(key, transposed_song.analyze('key'))\n",
    "    return transposed_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total song transposed 18\n"
     ]
    }
   ],
   "source": [
    "# list of transposed songs\n",
    "transposed_songs = []\n",
    "for song in Songs:\n",
    "    song = transpose(song)\n",
    "    transposed_songs.append(song)\n",
    "print('total song transposed', len(transposed_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_events(song):\n",
    "    # create an empty list which will contain information about notes and rests\n",
    "    notes_in_song = []\n",
    "    \n",
    "    # Iterate on each part in song\n",
    "    for part in song.parts:\n",
    "        # iterate over each event in the part\n",
    "        # create an empty list to collect information about notes and rests in each part\n",
    "        notes_in_part = []\n",
    "        \n",
    "        for event in part.flat:\n",
    "            # if the event is a note - the label is equal to the note number in midi, if it's a rest, then the label is a rest\n",
    "            # we will be based on the assumption that the Measure is divided into 16 bits. To do this, we will divide each event by 0.25(4/16)\n",
    "            if isinstance(event, note.Note):\n",
    "                cells = int(event.duration.quarterLength / 0.25)\n",
    "                for cell in range(cells):\n",
    "                    if cell == 0:\n",
    "                        notes_in_part.append(str(event.pitch.midi))\n",
    "                    else:\n",
    "                        notes_in_part.append('_')\n",
    "       \n",
    "            elif isinstance(event, note.Rest):\n",
    "                cells = int(event.duration.quarterLength / 0.25)\n",
    "                for cell in range(cells):\n",
    "                    if cell == 0:\n",
    "                        notes_in_part.append('rest')\n",
    "                    else:\n",
    "                        notes_in_part.append('_')\n",
    "            elif isinstance(event, chord.Chord):\n",
    "                cells = int(event.duration.quarterLength / 0.25)\n",
    "                for cell in range(cells):\n",
    "                    if cell == 0:\n",
    "                        notes_in_part.append(str(event.pitchedCommonName))\n",
    "                    else:\n",
    "                        notes_in_part.append('_')                \n",
    "                \n",
    "        # separator for splitting songs\n",
    "        notes_in_part.append('SEP')\n",
    "\n",
    "        notes_in_song.append(notes_in_part)\n",
    "        # print(len(notes_in_part), len(notes_in_song))\n",
    "        \n",
    "    return notes_in_song       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\warmo\\AppData\\Local\\Temp\\ipykernel_5824\\3081885485.py:4: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  collected = collect_events(song)\n"
     ]
    }
   ],
   "source": [
    "# list of collected events\n",
    "events = []\n",
    "for song in transposed_songs:\n",
    "    collected = collect_events(song)\n",
    "    events.append(collected)\n",
    "    # print(song.metadata.title)\n",
    "events = pd.DataFrame(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of unique events in our list (in all loaded songs)\n",
    "set_of_unique_keys = {x for l in events.sum() for x in l}\n",
    "vocabulary = dict(zip(set_of_unique_keys, range(len(set_of_unique_keys))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode final dataset with vocabulary\n",
    "final_events = []\n",
    "for i in range(len(events.sum())): \n",
    "    temporary = []\n",
    "    for j in events.sum()[i]:\n",
    "        temporary.append(vocabulary[j])\n",
    "    final_events.append(temporary)\n",
    "final_events = np.array(final_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('F:\\\\MusicNet\\\\КИШ\\\\vocabulary\\\\vocabulary.npy', vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataset\n",
    "def create_training_set(lenght, part):\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    for i in range(len(part) - lenght):\n",
    "        if part[i+lenght] != vocabulary['SEP']:\n",
    "            x_temp.append(part[i:i+lenght])\n",
    "            y_temp.append(part[i+lenght])            \n",
    "        else:\n",
    "            i += (lenght + 1)       \n",
    "    return x_temp, y_temp # np.array(x_temp), np.array(y_temp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainig sequences, with a given lenght - seq_len\n",
    "seq_len = 128\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(len(final_events)):    \n",
    "    x_temp, y_temp = create_training_set(seq_len, final_events[i])\n",
    "\n",
    "    x_train.append(x_temp)\n",
    "    y_train.append(y_temp)\n",
    "    \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 19304, 128) (2, 19304)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = to_categorical(x_train, num_classes=len(vocabulary))\n",
    "y = to_categorical(y_train, num_classes=len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train sequences and targets for each input of our network\n",
    "solo_train, bass_train = X[0], X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_target, bass_target = y[0], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_inputs = keras.Input(shape=(seq_len, len(vocabulary)), name='solo')\n",
    "bass_inputs = keras.Input(shape=(seq_len, len(vocabulary)), name='bass')\n",
    "# adding LSTM layer\n",
    "solo_lstm = keras.layers.LSTM(seq_len)(solo_inputs)\n",
    "bass_lstm = keras.layers.LSTM(seq_len)(bass_inputs)\n",
    "# concatenate inputs \n",
    "x = keras.layers.concatenate([solo_lstm, bass_lstm])\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "# 2 output layers\n",
    "solo_pred = keras.layers.Dense(len(vocabulary), activation='softmax', name='solo_pred')(x)\n",
    "bass_pred = keras.layers.Dense(len(vocabulary), activation='softmax', name='bass_pred')(x)\n",
    "model = keras.Model(inputs=[solo_inputs, bass_inputs], outputs=[solo_pred, bass_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=keras.losses.categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit({'solo': solo_train, 'bass': bass_train},\n",
    "          {'solo_pred': solo_target, 'bass_pred': bass_target},\n",
    "          epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тест таб 124.mid loaded\n",
      "Total songs loaded 1\n"
     ]
    }
   ],
   "source": [
    "# Loading test midi files whith metadata\n",
    "Songs = []\n",
    "directory = 'F:\\MusicNet\\КИШ\\TEST'\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f) and filename.endswith('.mid'):\n",
    "        f = converter.parse(f)\n",
    "        f.insert(0, metadata.Metadata())\n",
    "        f.metadata.title = filename\n",
    "        Songs.append(f)\n",
    "        print(f.metadata.title, 'loaded')\n",
    "print('Total songs loaded', len(Songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\warmo\\AppData\\Local\\Temp\\ipykernel_5824\\1663902473.py:4: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
      "  collected = collect_events(song)\n"
     ]
    }
   ],
   "source": [
    "# collecting events in test song\n",
    "test_events = []\n",
    "for song in Songs:\n",
    "    collected = collect_events(song)\n",
    "    test_events.append(collected)\n",
    "test_events = pd.DataFrame(events) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode test dataset with vocabulary\n",
    "test_final_events = []\n",
    "for i in range(len(test_events.sum())): \n",
    "    temporary = []\n",
    "    for j in test_events.sum()[i]:\n",
    "        temporary.append(vocabulary[j])\n",
    "    test_final_events.append(temporary)\n",
    "test_final_events = np.array(final_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19450, 83)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test to categorical and expand dimensions to network requirements\n",
    "test = to_categorical(test_final_events, len(vocabulary))\n",
    "test = np.expand_dims(test, axis=1)\n",
    "test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "solo_first, bass_first = test[0], test[1]\n",
    "solo, bass = [], []\n",
    "for i in range(64):\n",
    "    solo_next, bass_next = model.predict({'solo': solo_first,'bass': bass_first})\n",
    "    \n",
    "    for k in solo_next, bass_next:\n",
    "        k[np.where(k == np.random.choice(k[0], p=k[0]))] = 1\n",
    "        k[np.where(k != np.float32(1))] = 0\n",
    "\n",
    "    for j in solo_first, bass_first:\n",
    "        j = np.delete(j, 0, 1)\n",
    "        j = np.squeeze(j)\n",
    "        for k in solo_next, bass_next:\n",
    "            j = np.concatenate((j, k))\n",
    "        j = np.expand_dims(j, axis=1)\n",
    "        \n",
    "    solo.append(solo_next), bass.append(bass_next)    \n",
    "solo, bass = np.array(solo), np.array(bass)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode list with vocabulary \n",
    "total = []\n",
    "for i in solo, bass:\n",
    "    index_list = np.where(i == 1)[2]\n",
    "    temporary = []\n",
    "    for j in index_list:\n",
    "        temporary.append(list(k for k, v in vocabulary.items() if v == j))\n",
    "    total.append(temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert song to midi function\n",
    "def convert_to_midi(list_of_events, step_duration):\n",
    "    \n",
    "    part = stream.Stream()\n",
    "    first_symbol = None\n",
    "    counter = 1\n",
    "\n",
    "    for i, symbol in enumerate(list_of_events):\n",
    "\n",
    "                # handle case in which we have a note/rest\n",
    "                if symbol != \"_\" or i + 1 == len(list_of_events):\n",
    "\n",
    "                    # ensure we're dealing with note/rest beyond the first one\n",
    "                    if first_symbol is not None:\n",
    "\n",
    "                        quarter_length_duration = step_duration * counter # 0.25 * 4 = 1\n",
    "\n",
    "                        # handle rest\n",
    "                        if first_symbol == \"rest\":\n",
    "                            m21_event = note.Rest(quarterLength=quarter_length_duration)\n",
    "\n",
    "                        # handle note\n",
    "                        else:\n",
    "                            m21_event = note.Note(int(first_symbol), quarterLength=quarter_length_duration)\n",
    "\n",
    "                        part.append(m21_event)\n",
    "\n",
    "                        # reset the step counter\n",
    "                        counter = 1\n",
    "\n",
    "                    first_symbol = symbol\n",
    "\n",
    "                # handle case in which we have a prolongation sign \"_\"\n",
    "                else:\n",
    "                    counter += 1\n",
    "\n",
    "    return part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, B = np.squeeze(total[0]), np.squeeze(total[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert song with function\n",
    "song = stream.Score()\n",
    "for i in S, B:\n",
    "    song.insert(convert_to_midi(i, 0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save midi\n",
    "song.write('midi', 'F:\\\\MusicNet\\\\КИШ\\\\Generated\\\\generated128.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be796e9e6ba899f821774a1d83011cc1613f76a45856fc1a343da6674fc2af9c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
